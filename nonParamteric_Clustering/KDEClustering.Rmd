---
title: "KDE Clustering"
author: "Oliver Shipston-Sharman"
date: "06/06/2018"
output: html_document
---
# Kernel Density Estimation Clustering
The below script uses R functions developed by Genovese et al. to apply bandwidth sweeps and assess mode stability across n-dimensions in a kernerl density estimate based cluster number assessment.

It outputs 6 figures labelled 'MN' or 'OSS' depending on the datatable selected for the analysis below:
Figure 1: A plot of significant and non-signficant modes detected over the spectrum of bandwidths tested.
Figure 2: A scatter plot of cells and modes in the first two principal components of data colored according to cluster identity. Significant modes are plotted in blue, non-significant in red.
Figure 3: As above but colored according to experimenter.
Figure 4-6: Surface plotes of the KDE in 2 principal components highlighting topographic features of the KDE.

It is dependant upon scripts available at [link] https://sites.google.com/a/uniroma1.it/marcoperonepacifico/R-code
```{r}
source("genovese_scripts/modes.functions.r")
```

#### Map required libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gplots)
library(RColorBrewer)
library(MASS)
library(effsize)
library(lsr)
library(matrixcalc)
library(mvtnorm)
library(scatterplot3d)
# library(xlsx)
library(tsne)
library(lmerTest)
library(tidyverse)
library(lme4)
library(LMERConvenienceFunctions)
library(R.matlab)
```

#### Load Dataset
Load cell features from *datatables/txt*/ in the form of *features* x *observations* matrix. Can be in any space: raw feature, pricipal component, t-SNE, spectral decomposition etc.

Choose which datatable to use:
datatable.txt = NOLAN Lab selected dataset with 12 features n = 840 ? Selection criteria.
OSSFeatDat.txt = whole patch dataset with 11 features (did not assess FI) n = 1222.

```{r import data, message = FALSE}
# fname.sc <- "/Users/hughpastoll/Research/stellateintrinsic/Database/datatable.txt"
# fname.sc <- "raw_data/datatable.txt" # Import NOLANLab .txt datafile
fname.sc <- "raw_data/OSSFeatDat.txt" # Import OSS .txt datafile from MATLAB feature analysis

# Assign an identifier for figure plotting to differentiate datasets...
if(fname.sc=="raw_data/datatable.txt"){
  figStr = "MN"
} else if(fname.sc=="raw_data/OSSFeatDat.txt"){
  figStr = "OSS"
}

data.import <- read_tsv(fname.sc) 

# Strip out rows from data where locations are unknown (are NaN)
data.sc <- data.import %>% drop_na(dvloc)

# Convert dvloc from microns to millimetres - prevents errors in model fitting large dv values
data.sc <- mutate(data.sc, dvlocmm = dvloc/1000)

# Keep animals â‰¥ min_age
min_age <- 0
data.sc.old <- filter(data.sc, age >= min_age)

# Calculate number of observations per animal
counts.old <- data.sc.old %>% count(id)
#summary(counts.old)

normalize<-function(m){
   (m - mean(m, na.rm = TRUE))/sd(m, na.rm = TRUE)
}

normByMouse<-function(data.sc){
  dataNorm = data.sc
  for (M in unique(data.sc$id)){
    mdat = data.sc[data.sc$id == M,1:12]
    dataNorm[data.sc$id == M,1:ncol(mdat)] <- as.data.frame(lapply(mdat, normalize))
  }
  return(dataNorm)
}

stripnonNum <- function(str){
  str = gsub("[^0-9]","",str)
  return(str)
}

simplifyID <- function(str){
  sstr = strsplit(str,"_")
  nstr = gsub("[^0-9]","",sstr[[1]][2])
  return(nstr)
}

# data.sc.norm <- as.data.frame(normByMouse(data.sc)) # Normalize by mouse
data.sc.norm <- as.data.frame(lapply(data.sc[1:11], normalize)) # Normalize by all
data.sc.norm$dvlocmm <- data.sc$dvlocmm
data.sc.norm$id <- data.sc$id
data.sc.norm$housing <- data.sc$housing
data.sc.norm$expr <- data.sc$expr
```

#### Compute principle components
Reduce dimensionality of data to first three principal components.
```{r}
pca <- prcomp(data.sc.norm[1:11])
data.sc.pca <- as.data.frame(pca[["x"]])

# Specify which features or PCs to use in method.
dat = data.sc.pca[c("PC1","PC2","PC3")]
dat <- as.matrix(dat,nrow(dat),ncol(dat)) # Data must be in matrix form for genovese functions.
ncomp = ncol(dat)
```

#### Define spectrum of kernel widths/bandwidths
Genovese et al use pairwise distances between points to guide this (COMMENTED BELOW).
This turned out to be inconsistently useful so I tended to estimate my own limits. CAUTION choosing a bandwidth too small results in hundreds of modes requiring testing and makes running the script very slow.

The best method I found was to pick a wide range and run a low-resolution sweep to try and find where the number of modes reaches a steady state, then run a narrower and higher fidelity assessment of that approximate bandwidth. Bandwidth selection is the arbitrary parameter of this method and PDF clustering in general, it's objective selection has many methods reviewed here: [link] http://onlinelibrary.wiley.com/doi/10.1111/insr.12039/pdf.

Manual method
```{r}
bwmin = 0.5 # Minimum bandwidth.
bwmax = 1.5 # Maximum bandwidth.
ngrid = 25 # number of bandwidths to test
```

<!--
Genovese et al method...
```{r eval=FALSE, collapse=TRUE}
disran = matrix(,nrow=nrow(dat),ncol=2)
for(i in 1:nrow(dat)){
  ptdis = sqrt(rowSums(t(dat[i,]-t(dat))^2)) # distance of point dat[i,] from all data
   disran[i,] = range(ptdis[ptdis>0])
}
bwmin     = quantile(disran[2:nrow(disran),1], probs=0.98)
bwmax     = quantile(disran[2:nrow(disran),2], probs=0.2)
```-->

```{r}
bwgrid = seq(bwmin, bwmax, length=ngrid)
```

Preallocate matrices to store results.
```{r collapse=TRUE}
sigmods = matrix(,nrow=100,ncol=ncomp)
nsigmods = matrix(,nrow=length(bwgrid),ncol=1)
nmods = matrix(,nrow=length(bwgrid),ncol=1)
clidx = matrix(,nrow=nrow(dat),ncol=1)
```

Split data into two halves randomly for the purposes of the 'Telepathic Bootstrap'.
```{r}
samp = sample(x=1:nrow(dat), size=nrow(dat), replace=FALSE)
datX = dat[head(samp,nrow(dat)/2),1:ncol(dat)]
datY = dat[head(samp,nrow(dat)/2),1:ncol(dat)]
```

## Assess modality of Data
'multibandtest.fun' is the main function responsibe for testing the modes across the bandwidths. It constructs kernel density estimates of datX PDF at each kernel width. Finds every mode within the PDF via meanshift and assesses the *stability* of the mode in datY bootstrapping the other half of the data nboot times.

X = multibandtest.fun(datX, datY, bwgrid, nboot, alpha, digits,)  
**datX** = Half of data used to locate potential modes..
**datY** = Half of data used to test modes located in datX
**bwgrid** = array of bandwidths used to test the data.
**nboot** = number of resamples used in the bootstrap. 1000 is robust and the method is relatively efficient. But 500 yields good results and is quicker.
**alpha** = Confidence limit for hypothesis testing
**digits** = number of digits that located modes are rounded to. If too low seperate modes will be combined artificially. If too high the method will find far too many modes as the meanshift algorithm is only so accurate at locating the modes.  
**X** = datastructure containing the results of the mode testing procedure at every bandwidth.

```{r}
print('Computing bandwidth sweep, this may take some time depending on the number of modes...')
X = multibandtest.fun(datX, datY, bwgrid, nboot=1000, alpha=0.05, digits=2)

# Extract number of significant modes per bandwidth..
for(h in 1:length(bwgrid)){
	nsigmods[h] = sum(X[[h]][["CIlead"]][,2] < 0)
	nmods[h] = nrow(X[[h]][["CIlead"]])	
}
```

Find smallest bandwidth exhibiting maximum number of modes.
This is arguably not the best way to specify the optimal bandwidth. At very small bandwidths so many modes are identified and so many tested some are bound to obtain significance particularly if they are outliers. Comparing where the maximum number of significant modes is where the number of total modes remains stable for a prolonged period is probably a better if subjective approach.

```{r}
print(paste('Maximum no. of significant modes found = ',max(nsigmods),sep=''))
bwidx = which(!is.na(match(nsigmods, max(nsigmods))))
bwidx = bwidx[1] # 1 For smallest length(bwidx) for greatest
sidx = X[[bwidx]][["CIlead"]][,2] < 0
nsidx = X[[bwidx]][["CIlead"]][,2] > 0
appmods = matrix(X[[bwidx]][['modes']][sidx,],ncol=ncomp)
nappmods = matrix(X[[bwidx]][['modes']][nsidx,],ncol=ncomp)
```

The Genovese et al functions calculate cluster IDs but only for half of the data. Below is an adaptation of one of their function which uses the optimal bandwidth found previously to meanshift cluster the entire dataset. As this uses a KDE of the entire dataset the modes can be in slightly different locations.

```{r}
critical = round(matrix(t(apply(X=dat, MARGIN=1, FUN=msiter.fun, dat=dat, bw=bwgrid[bwidx])), ncol=ncol(dat)),digits=2) # Finds the cluster origin for every data point at the critical bandwidth

modes = modecl.fun(modemat=critical, digits=2)
# Assign Cluster ID based on modes found in entire dataset
for(pt in 1:nrow(critical)){
	for(M in 1:nrow(modes)){
		if(sum(modes[M,] == critical[pt,])==ncomp){
			clidx[pt] = M;
		}
	}
}
```

## Mode position figures
The below figures output as pdfs
Plotting Colors and figure directory.
```{r collapse=TRUE}
figDir = 'figures/'
colArray=list('deeppink2','lightseagreen','steelblue2','gray40','gray41','gray0','gray','gray39','gray40','gray41','gray0','gray','gray39','gray40','gray41','gray0','gray','gray39','gray40','gray41','gray0','gray','gray39','gray40','gray41','gray0','gray')
expColArray=list('gold1','darkslategray4')
```

### FIGURE 1: Line graph showing number of total vs number of significant modes found through the BW spectrum.
```{r}
print('Constructing Bandwidth Spectrum Figure')
pdf(file=paste(figDir,'1_',figStr,'_bandwidth_spectrum_fig.pdf',sep=''),
    width=21, height=7)
par(mar=c(5,5,5,0.1))
plot(y=nmods,x=bwgrid,type='o',col='steelblue2',xlim=c(min(bwgrid),max(bwgrid)),lwd=5,ylim=c(0,max(nmods)),xlab='',ylab='',bty='l',main='Bandwidth Spectrum Plot')
lines(y=nsigmods,x=bwgrid,type='o',col='dodgerblue4',lwd=5)
lines(x=c(bwgrid[bwidx],bwgrid[bwidx]),y=c(-1,50),lty=2,col='gray83',lwd=5)
legend("topright", legend = c('Significant Modes','Total Modes','Optimal Bandwidth'),col=c('dodgerblue4','steelblue2','gray83'),lty=c(1,1,2))
dev.off()
```

### FIGURE 2: Scatter figure of significant and non-significant modes with all datapoints colored according to clusterID
```{r}
print('Constructing Scatter Figures')
pdf(file=paste(figDir,'2_',figStr,'_modes_and_cluster_IDs.pdf',sep=''),
    width=15, height=7)
par(mar=c(5,5,5,5), mfrow=c(1,2))
# Scatter datasets
psize=1.2
plot(c(),xlab='PC1',ylab='PC2',xlim=range(dat[,1]), ylim=range(dat[,2]),main='Identified modes and corresponding cluster identities')
# Construct Cluster Scatter
for(M in 1:nrow(modes)){
	points(dat[clidx == M,1],dat[clidx == M,2],pch=20,cex=psize,col=colArray[[M]])
}
points(appmods[,1],appmods[,2],pch=20,cex=3,col='dodgerblue4')
points(nappmods[,1],nappmods[,2],pch=20,cex=3,col='firebrick2')
legend("topright", legend = c('Cluster 1','Cluster 2'),col=unlist(colArray[1:2]),pch=20,pt.cex=2)

# Construct Experimenter Scatter
plot(c(),xlab='PC1',ylab='PC2',xlim=range(dat[,1]), ylim=range(dat[,2]),main='Identified modes and experimenter identity')
# Scatter significant modes colored according to experimenter
i=1
for(E in unique(data.sc.norm$expr)){
	points(dat[data.sc.norm$expr == E,1],dat[data.sc.norm$expr == E,2],pch=20,cex=psize,col=expColArray[[i]])
  i=i+1
}
points(appmods[,1],appmods[,2],pch=20,cex=3,col='dodgerblue4')
points(nappmods[,1],nappmods[,2],pch=20,cex=3,col='firebrick2')
legend("topright", legend = c('HP','DG'),col=unlist(expColArray[1:2]),pch=20,pt.cex=2)

dev.off()
```

### FIGURE 3: Computes a t-SNE dimensionality reduction and plots the points according to previously found KDE cluster IDs.
t-SNE is not commonly used for clustering itself as the parameters are very difficult to specify objectively. It provided useful in verifying cluster IDs obtained from KDE though. Perplexity = scale at which potential groupings in the data are assessed (needs to be tailored to the specific dataset). Epoch = how often the function updates you on the progress. niter = number of iterations for map fitting. (1000 or more is best, <500 the map can be volatile and if stopped early can return local minima)
```{r}
epoch = 100
niter = 1000
perp = 80
bffr=1.1
print('Computing t-SNE map')
dr = tsne(dat, initial_config = NULL, k = 2, initial_dims = ncomp, perplexity = perp, max_iter = niter, min_cost = 0, epoch_callback=NULL, whiten = TRUE, epoch=epoch)	
print('Constructing t-sne scatter Figure')


pdf(file=paste(figDir,'3_',figStr,'_t-SNE_clusterID_figure.pdf',sep=''),
    width=15, height=7)
par(mar=c(5,5,5,5), mfrow=c(1,2))
# Construct Mode t-sne Scatter
plot(c(),main='t-SNE Colored by Cluster ID',xlab='t-SNE 1',ylab='t-SNE 2',xlim=range(dr[,1])*bffr,ylim=range(dr[,2])*bffr)
for(M in 1:nrow(modes)){
	points(dr[clidx == M,1],dr[clidx == M,2],pch=20,cex=psize,col=colArray[[M]])
}
legend("topright", legend = c('Cluster 1','Cluster 2'),col=unlist(colArray[1:2]),pch=20,pt.cex=2)

# Construct Experimenter t-sne Scatter
plot(c(),main='t-SNE Colored by Experimenter',xlab='t-SNE 1',ylab='t-SNE 2',xlim=range(dr[,1])*bffr,ylim=range(dr[,2])*bffr)
i=1
for(E in unique(data.sc.norm$expr)){
	points(dr[data.sc.norm$expr == E,1],dr[data.sc.norm$expr == E,2],pch=20,cex=psize,col=expColArray[[i]])
  i=i+1
}
legend("topright", legend = c('HP','DG'),col=unlist(expColArray[1:2]),pch=20,pt.cex=2)


dev.off()
```

## PDF Surface Plots
Specify plotting variables
```{r collapse=TRUE}
# Construct color ramp for surface plots..
K_n = 50
nbcol=100 # Resolution of surface color ramp
blucol = colorRampPalette(c('white','white','steelblue2','dodgerblue4'))(n = nbcol)
```

### FIGURE 4: Computes KDE at Optimal bandwidth and plots surface plot.
```{r}
print('Constructing Kernel Density Surface Figures')
pdf(file=paste(figDir,'4_',figStr,'_optimal_BW_surface.pdf',sep=''),
    width=7, height=7)
 par(mar=c(3,3,3,0.1))
K = kde2d(datY[,1] ,datY[,2] ,h=exp(bwgrid[bwidx]) ,n=K_n ,lims = c(min(dat[,1])-0.2,max(dat[,1])+0.2,min(dat[,2])-0.2,max(dat[,2])+0.2))
# Create own color palette
z=K[['z']]
ncz=K_n
nrz=ncz
zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]
facetcol <- cut(zfacet, nbcol)
persp(y=K[['y']],x=K[['x']],z=K[['z']],phi=45,theta=-25,xlab='',ylab='',zlab='',col=blucol[facetcol],lwd=0.1,main=paste('Kernel Width =',toString(round(bwgrid[bwidx],digits=2))),box=0)
dev.off()
```

### FIGURE 5: Computes KDE at very small BW and plots surface.
```{r}
pdf(file=paste(figDir,'5_',figStr,'_undersmoothed_BW_surface.pdf',sep=''),
    width=7, height=7)
 par(mar=c(3,3,3,0.1))
K = kde2d(datY[,1] ,datY[,2] ,h=exp(0.05) ,n=K_n ,lims = c(min(dat[,1])-0.2,max(dat[,1])+0.2,min(dat[,2])-0.2,max(dat[,2])+0.2))
# Create own color palette
z=K[['z']]
ncz=K_n
nrz=ncz
zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]
facetcol <- cut(zfacet, nbcol)
persp(y=K[['y']],x=K[['x']],z=K[['z']],phi=45,theta=-25,xlab='',ylab='',zlab='',col=blucol[facetcol],lwd=0.1,main=paste('Kernel Width =',toString(round(0.05,digits=2))),box=0)
dev.off()
```

### FIGURE 6: Computes KDE at very large BW and plots surface.
```{r}
pdf(file=paste(figDir,'6_',figStr,'_oversmoothed_BW_surface.pdf',sep=''),
    width=7, height=7)
 par(mar=c(3,3,3,0.1))
K = kde2d(datY[,1] ,datY[,2] ,h=exp(bwgrid[length(bwgrid)]) ,n=K_n ,lims = c(min(dat[,1])-0.2,max(dat[,1])+0.2,min(dat[,2])-0.2,max(dat[,2])+0.2))
# Creates own color palette
nbcol=100
blucol = colorRampPalette(c('white','white','steelblue2','dodgerblue4'))(n = nbcol)
z=K[['z']]
ncz=K_n
nrz=ncz
zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]
facetcol <- cut(zfacet, nbcol)
persp(y=K[['y']],x=K[['x']],z=K[['z']],phi=45,theta=-25,xlab='',ylab='',zlab='',col=blucol[facetcol],lwd=0.1,main=paste('Kernel Width =',toString(round(bwgrid[length(bwgrid)],digits=2))),box=0)
dev.off()
```

# Return Cluster identities
If analysis was carried out in OSSFeatDat return cluster identities found in analysis of larger OSSFeatDat.txt to whole OSSFeatDat file and ID matched cells in datatable.txt file.

Cells are matched by mouseID and rectime (datatable.txt has no cell ids).
Currently the cluster identities are only returned when analysis is run on the larger OSSFeatDat dataset as running KDE clustering on datatable.txt results in only one significant mode.

```{r}

if(figStr == "OSS"){
  data.sc$OSScluster <- clidx # Add cluster ID as variable in dataframe
  data.sc$numid <- unlist(lapply(data.sc$id, simplifyID))
  write.table(data.sc,file="raw_data/OSSFeatDatwClusters.txt",sep="\t") # Export at .txt file
  
  MNTable <- as.data.frame(read_tsv("raw_data/datatable.txt"))
  MNTable$numid <- unlist(lapply(MNTable$id, stripnonNum))
  for(C in 1:nrow(data.sc)){
    CId = data.sc$numid[C]
    idx = which(CId == MNTable$numid)
    for(i in idx){
      if(is.na(MNTable$rectime[i])==FALSE && is.na(data.sc$rectime[C])==FALSE){
        if(MNTable$rectime[i] == data.sc$rectime[C]){
          MNTable$OSScluster[i] <- data.sc$OSScluster[C]
        }
      } else {
        MNTable$rectime[i]=NaN
      }
    }
  }
  write.table(MNTable,file="raw_data/datatablewClusters.txt",sep="\t") # Export at .txt file
} else if (figStr == "MN"){
  print("Could not return cluster IDs to datatable on this run")
}
```